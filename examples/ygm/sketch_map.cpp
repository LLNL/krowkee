// Copyright 2021-2022 Lawrence Livermore National Security, LLC and other
// krowkee Project Developers. See the top-level COPYRIGHT file for detaisketch.
//
// SPDX-License-Identifier: MIT

#include <krowkee/hash/hash.hpp>
#include <krowkee/sketch.hpp>

#include <ygm/comm.hpp>
#include <ygm/container/map.hpp>

#include <iostream>
#include <random>

// We are using floats as our feature type in this example.
using register_type = float;

// This function computes squared l2 distance, and will be used to verify the
// guarantees of the Johnson-Lindenstrauss lemma.
template <typename T>
double l2_distance_sq(const std::vector<T> &lhs, const std::vector<T> &rhs) {
  assert(lhs.size() == rhs.size());
  double dist_sq(0);
  for (int i(0); i < lhs.size(); ++i) {
    dist_sq += std::pow(lhs[i] - rhs[i], 2);
  }
  return dist_sq;
}

int main(int argc, char **argv) {
  // We create the YGM communicator to be used. The example proceeds similarly
  // to `examples/sparse_jlt.cpp`, where we sample some large-dimensional data
  // on each rank, accumulate sketches, and insert those sketches into a
  // ygm::container::map.
  ygm::comm world(&argc, &argv);
  {
    uint64_t      stream_size(20000);
    std::uint64_t domain_size(16384);
    std::uint64_t observation_count(2);
    std::uint64_t seed(krowkee::hash::default_seed);
    bool          verbose(true);

    // Using krowkee requires the selection of a sketch type, here encapsulated
    // as `sketch_type`. We use the `SparseJLT` type defined in the simple API
    // in `krowkee/sketch.hpp`. This type has four template parameters:
    //   1. the numeric type to be used by each register (here `float`),
    //   2. a `std::size_t` parameter `range_size` indicating the number of
    //      registers used by each instance of the internal transform,
    //   3. a `std::size_t` parameter `replication_count` indicating the number
    //      of instances of the transform to be used, and
    //   4. a shared pointer type to be used by the shared transform object
    //      (`ygm::ygm_ptr` for shared memory implementations).
    constexpr const std::size_t range_size        = 8;
    constexpr const std::size_t replication_count = 2;
    using sketch_type =
        krowkee::sketch::SparseJLT<register_type, range_size, replication_count,
                                   ygm::ygm_ptr>;

    // Having established a sketch type, the first step to use a krowkee sketch
    // is to create a shared pointer to a transform functor. The sketch type
    // includes typedefs of the transform and pointer types. This is where the
    // random seed is used. Transforms of the same type sharing the same seed
    // will behave identically. As this is a distributed memory code, we create
    // a ygm::ygm_ptr of the transform to be used to define the sketch data
    // structures on each rank, ensuring that each uses the same transform.
    using transform_type     = typename sketch_type::transform_type;
    using transform_ptr_type = typename sketch_type::transform_ptr_type;
    transform_type     transform{seed};
    transform_ptr_type transform_ptr(world.make_ygm_ptr(transform));

    // We create a `ygm::container::map` that will hold the embeddings for each
    // of our sketches. We also create an empty sketch using our transform as
    // the default value.
    sketch_type                           default_sketch(transform_ptr);
    ygm::container::map<int, sketch_type> sketches(world, default_sketch);

    // We sample a data stream for each implicit large feature vector,
    // asynchronously sending an update to the associated sketch. In this
    // example each stream is generated by a particular rank, but in practice we
    // would do this if updates to a stream could appear on any rank. We are
    // careful to use a different random seed for each rank. This often occurs
    // when performing a parallel read of an edge list of a graph.
    std::mt19937 gen(krowkee::hash::wang64(seed + world.rank()));
    std::uniform_int_distribution<std::uint64_t> dist(0, domain_size - 1);
    for (int i(0); i < observation_count; ++i) {
      int index = observation_count * world.rank() + i;
      for (int j(0); j < stream_size; ++j) {
        // This remote lambda will be executed for each stream update, and will
        // be sent to the appropriate sketch on the appropriate rank.
        auto insert_lambda = [](const int &idx, sketch_type &sketch,
                                const std::uint64_t update) {
          sketch.insert(update);
        };
        sketches.async_visit(index, insert_lambda, dist(gen));
      }
    }
    world.barrier();

    world.cout0();
    world.cout0(
        "These are the (index, register) pairs resulting from each sketch on "
        "each rank:");

    // We prepare a datastructure to hold the scaled embeddings once all
    // sketches have accumulated. This is currently required, but the sketches
    // may perform scaling on insertion in a future version, in which case this
    // step is no longer necessary.
    ygm::container::map<int, std::vector<register_type>> embeddings(world);

    sketches.for_all([&embeddings](const int idx, const sketch_type &sketch) {
      embeddings.async_insert(idx, sketch.scaled_registers());
    });
    world.barrier();

    // We print out the found embeddings. At this point the user can use
    // `embeddings` as the feature vectors in a downstream algorithm.
    world.cout0();
    world.cout0(
        "These are the (index, register) pairs resulting from each sketch on "
        "each rank:");
    embeddings.for_all(
        [&world](const int idx, const std::vector<register_type> &embedding) {
          std::stringstream ss;
          ss << "has embedding (index " << idx << "):";
          for (const auto &reg : embedding) {
            ss << " " << reg;
          }
          world.cout(ss.str());
        });
  }

  return 0;
}